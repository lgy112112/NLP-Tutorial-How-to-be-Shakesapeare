{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory before change: /teamspace/studios/this_studio\n",
      "Directory changed to: NLP-Tutorial-How-to-be-Shakesapeare/Leave-Me-Alone\n",
      "Current directory after change: /teamspace/studios/this_studio/NLP-Tutorial-How-to-be-Shakesapeare/Leave-Me-Alone\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# è·å–å½“å‰å·¥ä½œç›®å½•\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current directory before change: {current_directory}\")\n",
    "\n",
    "# è¦æ›´æ”¹çš„ç›®æ ‡ç›®å½•\n",
    "target_directory = 'NLP-Tutorial-How-to-be-Shakesapeare/Leave-Me-Alone'\n",
    "\n",
    "# å¦‚æœå½“å‰ç›®å½•ä¸æ˜¯ç›®æ ‡ç›®å½•ï¼Œåˆ™æ›´æ”¹å½“å‰å·¥ä½œç›®å½•\n",
    "if not current_directory.endswith(target_directory):\n",
    "    os.chdir(target_directory)\n",
    "    print(f\"Directory changed to: {target_directory}\")\n",
    "else:\n",
    "    print(\"Already in the target directory.\")\n",
    "\n",
    "# è·å–æ›´æ”¹åçš„å½“å‰å·¥ä½œç›®å½•åœ°å€\n",
    "new_directory = os.getcwd()\n",
    "print(f\"Current directory after change: {new_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at pretrain_results/checkpoint-8682 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import random\n",
    "\n",
    "# åŠ è½½IMDbæ•°æ®é›†\n",
    "imdb_dataset = load_dataset('imdb')\n",
    "\n",
    "# éšæœºé€‰å–5000æ¡è®­ç»ƒæ ·æœ¬\n",
    "train_dataset = imdb_dataset['train'].shuffle(seed=42).select(range(5000))\n",
    "\n",
    "# åŠ è½½åˆ†è¯å™¨å’Œé¢„è®­ç»ƒçš„æ¨¡å‹\n",
    "model_path = 'pretrain_results/checkpoint-8682'\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# åˆ†è¯å’Œç¼–ç \n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# å¤„ç†æµ‹è¯•é›†\n",
    "test_dataset = imdb_dataset['test'].map(tokenize_function, batched=True)\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./train_results',\n",
    "    num_train_epochs=5,               # è®­ç»ƒè½®æ¬¡\n",
    "    per_device_train_batch_size=16,   # æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒæ‰¹é‡å¤§å°\n",
    "    per_device_eval_batch_size=16,    # æ¯ä¸ªè®¾å¤‡çš„è¯„ä¼°æ‰¹é‡å¤§å°\n",
    "    warmup_steps=500,                 # é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,                # æƒé‡è¡°å‡\n",
    "    logging_dir='./train_logs',             # æ—¥å¿—ç›®å½•\n",
    "    evaluation_strategy=\"epoch\",      # åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è¿›è¡Œè¯„ä¼°\n",
    "    save_strategy=\"epoch\",            # åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ä¿å­˜æ¨¡å‹\n",
    "    load_best_model_at_end=True,      # åœ¨è®­ç»ƒç»“æŸæ—¶åŠ è½½è¡¨ç°æœ€å¥½çš„æ¨¡å‹\n",
    "    metric_for_best_model=\"accuracy\", # é€‰æ‹©ç”¨äºæ¨¡å‹ä¿å­˜çš„æŒ‡æ ‡\n",
    ")\n",
    "\n",
    "# å®šä¹‰è®¡ç®—æŒ‡æ ‡çš„å‡½æ•°\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# åˆå§‹åŒ–Trainertrain\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 23:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.157512</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>0.944150</td>\n",
       "      <td>0.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.127132</td>\n",
       "      <td>0.949400</td>\n",
       "      <td>0.949311</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.949400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.048932</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>0.987291</td>\n",
       "      <td>0.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.008431</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.998600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 11:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.008430964313447475, 'eval_accuracy': 0.9986, 'eval_f1': 0.9985999992719949, 'eval_precision': 0.998600078432615, 'eval_recall': 0.9986, 'eval_runtime': 74.9263, 'eval_samples_per_second': 66.732, 'eval_steps_per_second': 4.177, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()\n",
    "\n",
    "# è®­ç»ƒç»“æŸåè¿›è¡Œè¯„ä¼°\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results on the test dataset: {'eval_loss': 0.41011637449264526, 'eval_accuracy': 0.92736, 'eval_f1': 0.9273554432684765, 'eval_precision': 0.9274672539278271, 'eval_recall': 0.92736, 'eval_runtime': 369.4631, 'eval_samples_per_second': 67.666, 'eval_steps_per_second': 4.23, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# åœ¨ test_dataset ä¸Šè¿›è¡Œè¯„ä¼°\n",
    "eval_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "\n",
    "# æ‰“å°è¯„ä¼°ç»“æœ\n",
    "print(f\"Evaluation results on the test dataset: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "# å®šä¹‰è®­ç»ƒå‚æ•°\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./train_results_baseline',\n",
    "    num_train_epochs=5,               # è®­ç»ƒè½®æ¬¡\n",
    "    per_device_train_batch_size=16,   # æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒæ‰¹é‡å¤§å°\n",
    "    per_device_eval_batch_size=16,    # æ¯ä¸ªè®¾å¤‡çš„è¯„ä¼°æ‰¹é‡å¤§å°\n",
    "    warmup_steps=500,                 # é¢„çƒ­æ­¥æ•°\n",
    "    weight_decay=0.01,                # æƒé‡è¡°å‡\n",
    "    logging_dir='./train_logs_baseline',             # æ—¥å¿—ç›®å½•\n",
    "    evaluation_strategy=\"epoch\",      # åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶è¿›è¡Œè¯„ä¼°\n",
    "    save_strategy=\"epoch\",            # åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ä¿å­˜æ¨¡å‹\n",
    "    load_best_model_at_end=True,      # åœ¨è®­ç»ƒç»“æŸæ—¶åŠ è½½è¡¨ç°æœ€å¥½çš„æ¨¡å‹\n",
    "    metric_for_best_model=\"accuracy\", # é€‰æ‹©ç”¨äºæ¨¡å‹ä¿å­˜çš„æŒ‡æ ‡\n",
    ")\n",
    "\n",
    "# å®šä¹‰è®¡ç®—æŒ‡æ ‡çš„å‡½æ•°\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# åˆå§‹åŒ–Trainertrain\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1565' max='1565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1565/1565 23:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.217484</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.913362</td>\n",
       "      <td>0.918428</td>\n",
       "      <td>0.913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.091083</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.974997</td>\n",
       "      <td>0.975153</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372700</td>\n",
       "      <td>0.029569</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>0.992420</td>\n",
       "      <td>0.992400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.018142</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.995800</td>\n",
       "      <td>0.995806</td>\n",
       "      <td>0.995800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "      <td>0.998400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1876' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 07:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.01005455944687128, 'eval_accuracy': 0.9984, 'eval_f1': 0.9984000012800051, 'eval_precision': 0.9984003220488245, 'eval_recall': 0.9984, 'eval_runtime': 75.013, 'eval_samples_per_second': 66.655, 'eval_steps_per_second': 4.173, 'epoch': 5.0}\n",
      "Test results on the test dataset: {'eval_loss': 0.01005455944687128, 'eval_accuracy': 0.9984, 'eval_f1': 0.9984000012800051, 'eval_precision': 0.9984003220488245, 'eval_recall': 0.9984, 'eval_runtime': 75.013, 'eval_samples_per_second': 66.655, 'eval_steps_per_second': 4.173, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "trainer.train()\n",
    "\n",
    "# è®­ç»ƒç»“æŸåè¿›è¡Œè¯„ä¼°\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 06:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results on the test dataset with the loaded baseline model: {'eval_loss': 0.425955206155777, 'eval_model_preparation_time': 0.0022, 'eval_accuracy': 0.92232, 'eval_f1': 0.9223193909840254, 'eval_precision': 0.9223332443705434, 'eval_recall': 0.92232, 'eval_runtime': 366.3155, 'eval_samples_per_second': 68.247, 'eval_steps_per_second': 4.267}\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒçš„ BERT æ¨¡å‹\n",
    "model_path = 'train_results_baseline/checkpoint-1565'\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# åˆå§‹åŒ–Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,  # ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„è®­ç»ƒå‚æ•°\n",
    "    eval_dataset=test_dataset,  # ä½¿ç”¨æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# åœ¨ test_dataset ä¸Šè¿›è¡Œè¯„ä¼°\n",
    "eval_results_baseline = trainer.evaluate()\n",
    "\n",
    "# æ‰“å°è¯„ä¼°ç»“æœ\n",
    "print(f\"Evaluation results on the test dataset with the loaded baseline model: {eval_results_baseline}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ€»çš„æ¥çœ‹ï¼Œé¢„è®­ç»ƒåçš„æ¨¡å‹æ•ˆæœæ˜¯æ›´ä¼˜çš„ã€‚\n",
    "\n",
    "åœ¨è®­ç»ƒä¸­çš„ç¬¬äºŒè½®å°±å±•ç°æ›´å¿«çš„æ”¶æ•›ã€‚\n",
    "\n",
    "åœ¨æœ€åçš„testä¸­ï¼Œé¢„è®­ç»ƒæ¨¡å‹ä¹Ÿæ˜¯åœ¨loss/acc/f1/recall/precæŒ‡æ ‡ä¸Šä¼˜äºbaselineæ¨¡å‹ï¼ˆä½ å°±è¯´é«˜ä¸€ç‚¹æ˜¯ä¸æ˜¯é«˜å§ï¼‰ã€‚"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
